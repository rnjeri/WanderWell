{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pyspark as ps    # for the pyspark suite\n",
    "import os               # for environ variables in Part 3\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .appName(\"df lecture\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import NGram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### this is for converting a silly pandas format to something that is more like a normal json you may want it later\n",
    "\n",
    "# panda = items.toPandas()\n",
    "\n",
    "# pcols = panda.columns\n",
    "\n",
    "# pcols = cycle(pcols)\n",
    "\n",
    "# jint = 0\n",
    "# jlist = []\n",
    "# jdict = {}\n",
    "\n",
    "# for i in panda.values.flatten():\n",
    "#     key = pcols.next()\n",
    "#     jdict[key] = i\n",
    "#     if key == 'user_id':\n",
    "#         jlist.append(jdict)\n",
    "#         jdict = {}\n",
    "#         jint += 1\n",
    "   \n",
    "\n",
    "\n",
    "# with open('../data/acc_dataset_local.json', 'w') as jfile:\n",
    "#     json.dump(jlist, jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# yelp = spark.read.json('../data/yelp_academic_reviews.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp = spark.read.json('../data/acc_dataset_local.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yelp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kill_non_ascii(text):\n",
    "    lets = []\n",
    "    ntext = text.lower()\n",
    "    ntext = re.sub(\"[^a-z' ]\",' ',ntext)\n",
    "#     for letter in ntext:\n",
    "#         if ord(letter) < 128 :\n",
    "#             lets.append(letter.lower())\n",
    "    return ntext.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spark.udf.register('sbin', lambda x: 1 if x > 3 else 0)\n",
    "spark.udf.register('imbin', lambda x: 1 if x > 2 else 0)\n",
    "spark.udf.register('mkascii', kill_non_ascii)\n",
    "spark.udf.register('listjoin', lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yelp.registerTempTable('yelp')\n",
    "\n",
    "r_bin =  spark.sql('''\n",
    "            SELECT array(mkascii(text)) as content, int(imbin(useful + funny + cool)) as relevant, int(sbin(stars)) as good\n",
    "            FROM yelp\n",
    "        ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(content=[u'[saturday, night, late, i, was, getting, warm, when, i, checked, the, thermostat, to, see, if, the, central, ac, was, on, and, yes, it, was, but, it, was, blowing, warm, air, oh, no, so, now, my, air, conditioning, decided, the, day, it, was, degrees, to, stop, working, i, called, sunday, afternoon, and, spoke, with, mark, i, told, him, about, the, issue, with, my, ac, and, he, said, the, earliest, he, could, get, here, was, sometime, monday, i, was, fine, with, that, even, tough, it, was, degrees, in, the, house, my, wife, and, i, were, ok, but, a, bit, worried, about, our, dogs, and, how, they, would, take, the, heat, amy, marks, wife, called, this, morning, to, confirm, that, i, would, be, home, mark, came, around, asked, a, few, questions, and, went, right, to, work, after, diagnosing, the, problem, he, came, back, and, told, us, what, was, wrong, what, needed, to, be, done, and, the, cost, to, have, it, repaired, i, agreed, to, the, repair, about, hour, later, he, was, done, i, believe, he, was, here, for, a, total, of, thirty, minutes, and, my, central, air, conditioning, unit, is, now, working, and, blowing, cold, air, happy, dance, he, located, tested, and, fixed, the, problem, bad, capacitor, quickly, and, efficiently, i, can, sit, back, now, and, relax, in, my, fully, air, conditioned, house, and, enjoy, the, cool, air, as, i, write, this, review, price, no, hidden, or, extra, fees, for, an, estimate, just, the, cost, of, the, repair, service, mark, is, very, professional, overall, this, company, was, as, good, as, you, could, ask, for, conclusion, they, were, prompt, thorough, and, affordable, and, highly, recommend, in, fact, yelp, readers, look, no, further, this, is, a, quality, ethical, reasonably, priced, a, c, service, could, not, be, happier]'], relevant=1, good=1)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_bin.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mincount =  r_bin.filter('relevant > 0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_neg = r_bin.filter('relevant = 0').orderBy(rand()).limit(mincount)\n",
    "dataset_pos = r_bin.filter('relevant = 1').orderBy(rand()).limit(mincount)\n",
    "\n",
    "df_relevance = dataset_pos.union(dataset_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_relevance = df_relevance.drop('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- relevant: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_relevance.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"content\", outputCol=\"filtered\")\n",
    "df_rel_stopped = remover.transform(df_relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- relevant: integer (nullable = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rel_stopped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram = NGram(n=2, inputCol=\"filtered\", outputCol=\"ngrams\")\n",
    "\n",
    "ngramDataFrame = ngram.transform(df_rel_stopped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- content: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- relevant: integer (nullable = true)\n",
      " |-- filtered: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- ngrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngramDataFrame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_rel_stopped.registerTempTable('df_rel_stopped')\n",
    "\n",
    "stop_strings = spark.sql('''\n",
    "            SELECT listjoin(filtered) as filtered, content, relevant\n",
    "            FROM df_rel_stopped\n",
    "            ''')\n",
    "\n",
    "### add ngrams later if needed\n",
    "# ngramDataFrame.registerTempTable('ngrammed_stopped_rel')\n",
    "\n",
    "# stop_strings = spark.sql('''\n",
    "#             SELECT listjoin(filtered) as filtered, ngrams, content, relevant\n",
    "#             FROM ngrammed_stopped_rel\n",
    "#             ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"filtered\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(stop_strings)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2500)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "# rescaledData.select(\"label\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- filtered: string (nullable = true)\n",
      " |-- content: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- relevant: integer (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- rawFeatures: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(2500, {61: 3.2888, 117: 1.9087, 132: 1.286, 224: 1.8984, 232: 2.193, 297: 0.4224, 405: 2.6723, 614: 1.1202, 666: 1.6664, 696: 0.8122, 813: 4.201, 855: 1.2046, 906: 1.1156, 1103: 0.9572, 1142: 4.3087, 1171: 3.3924, 1183: 3.662, 1184: 0.2636, 1207: 2.9454, 1220: 1.1831, 1309: 2.765, 1388: 2.9338, 1468: 0.5055, 1658: 4.9574, 1663: 4.6917, 1685: 0.3915, 1768: 1.6893, 1848: 0.8515, 1863: 2.3563, 1873: 2.0015, 1946: 0.6801, 2092: 1.977, 2096: 2.6723, 2139: 3.6502, 2179: 1.2547, 2200: 0.3792, 2299: 2.713, 2304: 2.258, 2432: 9.5186, 2459: 4.0675, 2473: 2.8406}))"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledData.printSchema()\n",
    "\n",
    "rescaledData.select('features').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autostem(cell):\n",
    "    return cell.asDict()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(count(text)=4153150)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register('pstem', autostem )\n",
    "\n",
    "all_corpus = spark.sql('''\n",
    "                    SELECT count(text)\n",
    "                    FROM yelp\n",
    "                    '''\n",
    "                    )\n",
    "\n",
    "all_corpus.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
